# Batch Operations Example

Demonstrates performance optimization through batch operations in the HOT cache library.

## What it does

- Compares individual vs batch operation performance
- Shows how batch operations can be significantly faster
- Demonstrates batch operations with different eviction policies
- Tests various data types with batch operations

## Key Features Demonstrated

- **Performance Comparison**: Individual vs batch Set/Get operations
- **Batch SetMany**: Store multiple items at once
- **Batch GetMany**: Retrieve multiple items efficiently
- **Different Policies**: LRU, LFU, ARC, 2Q, FIFO with batch operations
- **Data Types**: Strings, integers, floats with batch operations

## Quick Start

```bash
go run batch-operations.go
```

## Expected Output

```
ğŸ“¦ Batch Operations Example
===========================

ğŸ“ Example 1: Individual vs Batch Set
--------------------------------------
ğŸ”„ Testing individual Set operations...
â±ï¸ Individual Set: 100 operations in 2.5ms
ğŸ”„ Testing batch SetMany operations...
â±ï¸ Batch SetMany: 100 operations in 0.8ms
ğŸš€ Performance improvement: 3.1x faster

ğŸ“ Example 2: Individual vs Batch Get
--------------------------------------
ğŸ”„ Testing individual Get operations...
â±ï¸ Individual Get: 100 operations in 1.2ms
ğŸ”„ Testing batch GetMany operations...
â±ï¸ Batch GetMany: 100 operations in 0.4ms
ğŸš€ Performance improvement: 3.0x faster

ğŸ”„ Example 3: Batch Operations with Different Policies
------------------------------------------------------
âœ… LRU: 100/100 items in 0.8ms
âœ… LFU: 100/100 items in 0.9ms
âœ… ARC: 100/100 items in 1.1ms
âœ… 2Q: 100/100 items in 0.7ms
âœ… FIFO: 100/100 items in 0.9ms
```

## Performance Benefits

Batch operations are typically **2-4x faster** than individual operations because they:
- Reduce function call overhead
- Minimize lock contention
- Optimize memory allocations
- Improve cache locality
